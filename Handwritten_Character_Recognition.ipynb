{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwritten Character Recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCzToQsvHlZ6H9+XrfZWHx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itslokeshrawat/Handwritten-Character-Recognition/blob/main/Handwritten_Character_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing all Libraries"
      ],
      "metadata": {
        "id": "_cmMR4ZJtO8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "2F5hiUZ4tN3-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the data"
      ],
      "metadata": {
        "id": "TZQE24gBuP4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(r\"/content/A_Z Handwritten Data.csv\").astype('float32')\n",
        "\n",
        "print(data.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_xW7zJwuQjB",
        "outputId": "00173424-8ef1-4954-b442-2bfcc37f72d3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...  0.639  0.640  0.641  \\\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
            "6  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
            "7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
            "8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
            "9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
            "\n",
            "   0.642  0.643  0.644  0.645  0.646  0.647  0.648  \n",
            "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "5    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "6    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "7    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "8    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "9    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "\n",
            "[10 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data into images and their labels"
      ],
      "metadata": {
        "id": "nkGv4FC5vb2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('0',axis = 1)\n",
        "y = data['0']"
      ],
      "metadata": {
        "id": "VmiMyirzvdFF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaping the data in the csv file so that it can be displayed as an image"
      ],
      "metadata": {
        "id": "9SxKBtkHvfbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "train_x = np.reshape(train_x.values, (train_x.shape[0], 28,28))\n",
        "test_x = np.reshape(test_x.values, (test_x.shape[0], 28,28))\n",
        "\n",
        "print(\"Train data shape: \", train_x.shape)\n",
        "print(\"Test data shape: \", test_x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxG5UHiDvlSV",
        "outputId": "8202a373-c797-46b2-93e4-05c563ad468e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape:  (2236, 28, 28)\n",
            "Test data shape:  (560, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the labels are present in the form of floating point values, that we convert to integer values, & so we create a dictionary word_dict to map the integer values with the characters."
      ],
      "metadata": {
        "id": "P8lPNQgnvv-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_dict = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X', 24:'Y',25:'Z'}"
      ],
      "metadata": {
        "id": "Y-lQPKivvw2V"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the number of alphabets in the dataset"
      ],
      "metadata": {
        "id": "xEPrQNsxv0wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_int = np.int0(y)\n",
        "count = np.zeros(26, dtype='int')\n",
        "for i in y_int:\n",
        "    count[i] +=1\n",
        "\n",
        "alphabets = []\n",
        "for i in word_dict.values():\n",
        "    alphabets.append(i)\n",
        "\n",
        "fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
        "ax.barh(alphabets, count)\n",
        "\n",
        "plt.xlabel(\"Number of elements \")\n",
        "plt.ylabel(\"Alphabets\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wwPQ3mOtv1V2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffling the data"
      ],
      "metadata": {
        "id": "JYymUZnwwGYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shuff = shuffle(train_x[:100])\n",
        "\n",
        "fig, ax = plt.subplots(3,3, figsize = (10,10))\n",
        "axes = ax.flatten()\n",
        "\n",
        "for i in range(9):\n",
        "    _, shu = cv2.threshold(shuff[i], 30, 200, cv2.THRESH_BINARY)\n",
        "    axes[i].imshow(np.reshape(shuff[i], (28,28)), cmap=\"Greys\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WFsfC08TwIB9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Reshaping"
      ],
      "metadata": {
        "id": "GVO_a7YHwTTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2],1)\n",
        "print(\"New shape of train data: \", train_X.shape)\n",
        "\n",
        "test_X = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2],1)\n",
        "print(\"New shape of train data: \", test_X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7oy2sNcwT6m",
        "outputId": "ddf12fd6-a887-436b-b0b8-51a7b988083e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New shape of train data:  (2236, 28, 28, 1)\n",
            "New shape of train data:  (560, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we reshape the train & test image dataset so that they can be put in the model."
      ],
      "metadata": {
        "id": "dBk2Lt2uxC7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_yOHE = to_categorical(train_y, num_classes = 26, dtype='int')\n",
        "print(\"New shape of train labels: \", train_yOHE.shape)\n",
        "\n",
        "test_yOHE = to_categorical(test_y, num_classes = 26, dtype='int')\n",
        "print(\"New shape of test labels: \", test_yOHE.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddP3yy7Pw7Xb",
        "outputId": "87cf107f-d3ea-41f9-946e-c0d0f7ae8dab"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New shape of train labels:  (2236, 26)\n",
            "New shape of test labels:  (560, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN stands for Convolutional Neural Networks that are used to extract the features of the images using several layers of filters.\n",
        "The model created is as follows:"
      ],
      "metadata": {
        "id": "fWlvuzwPxE_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64,activation =\"relu\"))\n",
        "model.add(Dense(128,activation =\"relu\"))\n",
        "\n",
        "model.add(Dense(26,activation =\"softmax\"))\n",
        "#Above we have the CNN model that we designed for training the model over the training dataset."
      ],
      "metadata": {
        "id": "wn_dNFixxTN4"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling & Fitting Model"
      ],
      "metadata": {
        "id": "jzw8Dd1nxa58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as np_utils"
      ],
      "metadata": {
        "id": "7dMrO-elyBdD"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_X, train_yOHE, epochs=1,  validation_data = (test_X,test_yOHE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfUWnobIyYv3",
        "outputId": "fe9b9c8f-16fc-4eab-c78b-5686780ef316"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/70 [==============================] - 5s 48ms/step - loss: 0.3128 - accuracy: 0.9857 - val_loss: nan - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "model.save(r'model_hand.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L8GCa4A0CT3",
        "outputId": "7dba1c8a-ce03-4f2a-cb3c-bb1a52e41051"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2, 2, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 26)                3354      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 137,178\n",
            "Trainable params: 137,178\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting the Train & Validation Accuracies & Losses"
      ],
      "metadata": {
        "id": "I25A94nm0HVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The validation accuracy is :\", history.history['val_accuracy'])\n",
        "print(\"The training accuracy is :\", history.history['accuracy'])\n",
        "print(\"The validation loss is :\", history.history['val_loss'])\n",
        "print(\"The training loss is :\", history.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xapaedmn0HzQ",
        "outputId": "c845fb92-36ac-4fd7-b819-9c3563b8f5b4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The validation accuracy is : [1.0]\n",
            "The training accuracy is : [0.9856887459754944]\n",
            "The validation loss is : [nan]\n",
            "The training loss is : [0.3127700090408325]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing Some Predictions on Test Data"
      ],
      "metadata": {
        "id": "MNcw-AxK0ORw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3,3, figsize=(8,9))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i,ax in enumerate(axes):\n",
        "    img = np.reshape(test_X[i], (28,28))\n",
        "    ax.imshow(img, cmap=\"Greys\")\n",
        "    \n",
        "    pred = word_dict[np.argmax(test_yOHE[i])]\n",
        "    ax.set_title(\"Prediction: \"+pred)\n",
        "    ax.grid()"
      ],
      "metadata": {
        "id": "ltvjhTmA0NZ5"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing Prediction on External Image"
      ],
      "metadata": {
        "id": "BW3Il01H0U8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(r'/content/Wrought Iron Letter L.jfif')\n",
        "img_copy = img.copy()\n",
        "\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img = cv2.resize(img, (400,440))"
      ],
      "metadata": {
        "id": "yuLyHh360Vxo"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_copy = cv2.GaussianBlur(img_copy, (7,7), 0)\n",
        "img_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
        "_, img_thresh = cv2.threshold(img_gray, 100, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "img_final = cv2.resize(img_thresh, (28,28))\n",
        "img_final =np.reshape(img_final, (1,28,28,1))"
      ],
      "metadata": {
        "id": "jjphbjWz1Eay"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "whrWswHj1b45"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_pred = word_dict[np.argmax(model.predict(img_final))]\n",
        "\n",
        "cv2.putText(img, \"Dataflair _ _ _ \", (20,25), cv2.FONT_HERSHEY_TRIPLEX, 0.7, color = (0,0,230))\n",
        "cv2.putText(img, \"Prediction: \" + img_pred, (20,410), cv2.FONT_HERSHEY_DUPLEX, 1.3, color = (255,0,30))"
      ],
      "metadata": {
        "id": "gQcp92P31Gve"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we are setting up a waitKey in a while loop that will be stuck in loop until Esc is pressed, & when it gets out of loop using cv2.destroyAllWindows() we destroy any active windows created to stop displaying the frame.\n",
        "while (1):\n",
        "    k = cv2.waitKey(1) & 0xFF\n",
        "    if k == 27:\n",
        "        break\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "I16xYPZK3jyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have successfully developed Handwritten character recognition (Text Recognition) with Python, Tensorflow, and Machine Learning libraries."
      ],
      "metadata": {
        "id": "sZsYK0v93-0f"
      }
    }
  ]
}